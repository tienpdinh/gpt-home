\documentclass[12pt]{article} 
\usepackage[margin=1.1in]{geometry} 
\usepackage{indentfirst}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{longtable}
\usepackage{array}
\usepackage{booktabs}

\title{GPT-Home: A ChatGPT Fork for Smart Home Control Using Natural Language}
\author{Tien Dinh\\\texttt{PDinh@my.harrisburgu.edu}}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Smart home technology has widespread adoption yet significant usability gaps persist in current control interfaces. While voice assistants offer natural language capability, they require cloud connectivity and raise privacy concerns. This project, GPT-Home, develops a specialized ChatGPT-like system for local smart home control using lightweight language models deployed on edge hardware.

GPT-Home will leverage quantized language models (TinyLlama-1.1B or Phi-2 Q4) fine-tuned for smart home commands and deployed on a 4-node Raspberry Pi 4B cluster using Kubernetes (K3s). Unlike cloud-based solutions, this system operates entirely offline, ensuring privacy while demonstrating conversational AI feasibility on resource-constrained hardware. The architecture integrates directly with HomeAssistant through REST APIs, enabling natural language control without external dependencies.

This edge AI approach addresses privacy concerns in smart homes while exploring optimization strategies for deploying language models on commodity hardware. The project contributes to understanding edge AI deployment trade-offs and demonstrates how domain-specific models can deliver functional conversational interfaces in resource-constrained environments.
\end{abstract}

\section{Introduction}

Smart home systems like HomeAssistant, SmartThings, and Apple HomeKit have gained popularity, but significant usability gaps persist~\cite{yang2019smart}. Current control methods require complex interfaces, specific command phrasing, or vendor-specific applications. While voice assistants like Alexa and Google Assistant offer natural language capability, they remain limited in contextual understanding, require cloud connectivity, and raise privacy concerns~\cite{wilson2020privacy}.

GPT-Home is a specialized conversational AI system designed for intuitive, local control of smart home devices. Operating entirely on edge hardware (Raspberry Pi cluster), it eliminates privacy concerns while enabling offline operation. The system demonstrates practical application of lightweight language models in resource-constrained environments using optimization techniques like quantization~\cite{jacob2018quantization} and domain-specific fine-tuning.

The intersection of edge AI~\cite{shi2016edge} and smart home automation addresses critical concerns about data privacy, network latency, and internet dependency while maintaining sophisticated natural language understanding based on transformer architectures~\cite{vaswani2017attention}. This approach is particularly relevant as consumers seek alternatives to always-listening cloud-based assistants.

\section{Problem Statement}

Current smart home control interfaces suffer from three critical limitations that impede widespread adoption and user satisfaction. First, existing voice assistants require constant internet connectivity and transmit private home data to cloud servers, creating significant privacy vulnerabilities and rendering systems unusable during network outages. Second, these systems lack contextual understanding and conversational memory, forcing users to repeat device names and context in every interaction rather than enabling natural dialogue. Third, current interfaces require precise command phrasing and cannot handle the varied, natural language expressions that users intuitively employ when communicating about their home environment.

These limitations result in user frustration, privacy concerns, and over-reliance on cloud infrastructure for basic home automation tasks. The problem is particularly acute for privacy-conscious users who desire sophisticated natural language control without compromising personal data security. Additionally, the inability to maintain conversational context prevents users from engaging in natural, multi-turn dialogues about their home environment, forcing them to adapt their communication style to rigid system constraints rather than the system adapting to natural human communication patterns.

GPT-Home addresses this problem by developing a privacy-first, conversational AI system that operates entirely on local edge hardware while providing sophisticated natural language understanding and contextual awareness for smart home control. The project scope encompasses developing, deploying, and evaluating this system on resource-constrained hardware to demonstrate that advanced conversational AI capabilities can be achieved without cloud dependencies or privacy compromises.

\section{Requirements Analysis}

\subsection{Functional Requirements}

\begin{enumerate}[label=FR-\arabic*]
\item \textbf{Natural Language Processing}
    \begin{itemize}
    \item The system shall accept natural language commands in English for device control
    \item The system shall interpret varied phrasings for the same device operations
    \item The system shall handle ambiguous commands by requesting clarification
    \end{itemize}

\item \textbf{Device Control and Integration}
    \begin{itemize}
    \item The system shall integrate with HomeAssistant via REST API
    \item The system shall control lights, switches, sensors, and climate devices
    \item The system shall retrieve and display current device states
    \end{itemize}

\item \textbf{Conversational Context Management}
    \begin{itemize}
    \item The system shall maintain conversation history for context awareness
    \item The system shall remember device references within conversation sessions
    \item The system shall support follow-up commands without repeating device names
    \end{itemize}

\item \textbf{User Interface}
    \begin{itemize}
    \item The system shall provide a web-based chat interface
    \item The system shall display conversation history and device status
    \item The system shall provide real-time response generation
    \end{itemize}

\item \textbf{Model Management}
    \begin{itemize}
    \item The system shall load and run quantized language models locally
    \item The system shall support model switching between TinyLlama and Phi-2
    \item The system shall fine-tune models on smart home command datasets
    \end{itemize}
\end{enumerate}

\subsection{Non-Functional Requirements}

\begin{enumerate}[label=NFR-\arabic*]
\item \textbf{Performance Requirements}
    \begin{itemize}
    \item Response time shall be under 3 seconds for simple commands
    \item The system shall handle concurrent user sessions (minimum 2 users)
    \item Memory usage shall not exceed 3GB per Raspberry Pi node
    \end{itemize}

\item \textbf{Reliability and Availability}
    \begin{itemize}
    \item The system shall maintain 95\% uptime during normal operation
    \item The system shall gracefully handle model loading failures
    \item The system shall recover from individual node failures in the cluster
    \end{itemize}

\item \textbf{Security and Privacy}
    \begin{itemize}
    \item All processing shall occur locally without external data transmission
    \item Conversation data shall be stored locally
    \item The system shall not require internet connectivity for core functionality
    \end{itemize}

\item \textbf{Scalability}
    \begin{itemize}
    \item The system shall support horizontal scaling across cluster nodes
    \item The system shall handle up to 50 HomeAssistant devices
    \item The architecture shall support additional model deployment
    \end{itemize}

\item \textbf{Usability}
    \begin{itemize}
    \item The interface shall be intuitive for non-technical users
    \item The system shall provide helpful error messages and suggestions
    \item Response language shall be conversational and natural
    \end{itemize}

\item \textbf{Maintainability}
    \begin{itemize}
    \item The system shall use containerized deployment for easy updates
    \item Code shall follow established Python and API design patterns
    \item The system shall provide logging and monitoring capabilities
    \end{itemize}
\end{enumerate}

\section{Software Requirements Specification (SRS)}

\subsection{System Overview}
GPT-Home is a distributed conversational AI system deployed on a Kubernetes cluster that provides natural language control for smart home devices through local language model inference and HomeAssistant integration.

\subsection{System Architecture}
The system consists of four primary components: the Natural Language Processing Engine running quantized language models, the Device Integration Layer providing HomeAssistant connectivity, the Context Management System maintaining conversation state, and the User Interface providing web-based interaction.

\subsection{Data Requirements}
The system manages conversation histories, device states, model parameters, and user preferences. All data storage occurs locally using persistent volumes in the Kubernetes cluster.

\subsection{Interface Requirements}
External interfaces include HomeAssistant REST API for device communication, web browser interface for user interaction, and Kubernetes API for system management. Internal interfaces connect the language model, context manager, and device controller components.

\subsection{Quality Attributes}
Performance targets include sub-3-second response times and efficient memory utilization within 4GB constraints. Reliability requirements specify graceful degradation and error recovery. Security mandates local-only processing and encrypted data storage.

\section{UML Diagrams}

\subsection{Use Case 1: Basic Device Control}
\noindent\textbf{Actor:} Home User \\
\textbf{Goal:} Control a smart home device using natural language \\
\textbf{Preconditions:} User is authenticated, GPT-Home system is running, target device is available in HomeAssistant

\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{GPT-Home-Use-Case-1.png}
\caption{GPT-Home Basic Device Control Use Case Diagram}
\label{fig:usecase1}
\end{figure}

\subsection{Use Case 2: Contextual Conversation}
\noindent\textbf{Actor:} Home User \\
\textbf{Goal:} Control multiple devices through conversational context \\
\textbf{Preconditions:} User has active conversation session, previous commands established context

\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{GPT-Home-Use-Case-2.png}
\caption{GPT-Home Contextual Conversation Use Case Diagram}
\label{fig:usecase2}
\end{figure}

\pagebreak

\subsection{Use Case 3: Device Status Inquiry}
\noindent\textbf{Actor:} Home User \\
\textbf{Goal:} Query current status of smart home devices \\
\textbf{Preconditions:} GPT-Home system is running, HomeAssistant has current device data

\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{GPT-Home-Use-Case-3.png}
\caption{GPT-Home Device Status Inquiry Use Case Diagram}
\label{fig:usecase3}
\end{figure}

\subsection{Class Diagram}

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{class-diagram.png}
\caption{GPT-Home Class Diagram}
\label{fig:class}
\end{figure}

The class diagram shows the main system components and their relationships:

\textbf{GPTHomeController:} Main orchestration class managing user requests and coordinating between components.

\textbf{LanguageModel:} Handles loading, running, and managing the quantized language models (TinyLlama or Phi-2).

\textbf{ConversationManager:} Maintains conversation context, history, and manages multi-turn dialogue state.

\textbf{HomeAssistantIntegrator:} Interfaces with HomeAssistant REST API for device control and status queries.

\textbf{DeviceManager:} Manages device state, handles device discovery, and maintains device registry.

\textbf{UserInterface:} Web-based interface handling user input and displaying responses.

\textbf{ConfigurationManager:} Manages system configuration, model parameters, and deployment settings.

\subsection{Sequence Diagrams}

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{sequence-device-control.png}
\caption{Device Control Sequence Diagram}
\label{fig:seq-control}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{sequence-status-query.png}
\caption{Status Query Sequence Diagram}
\label{fig:seq-status}
\end{figure}

The sequence diagrams illustrate the message flow for two primary scenarios:

\textbf{Device Control Sequence:} Shows the interaction flow when a user issues a device control command, from initial input through language processing, device identification, HomeAssistant integration, and response generation.

\textbf{Status Query Sequence:} Demonstrates the process for handling device status inquiries, including context resolution, API queries, and formatted response delivery.

\section{Project Objectives}

\begin{enumerate}
\item Develop a fine-tuned lightweight LLM (TinyLlama-1.1B or quantized Phi-2) optimized for smart home control within edge hardware constraints
\item Create streamlined integration connecting the language model directly with HomeAssistant APIs without intermediate messaging layers
\item Implement context awareness and conversation management in memory-constrained environments
\item Design and deploy a secure local system on a Raspberry Pi K3s cluster eliminating cloud dependencies
\item Evaluate performance and resource utilization, comparing edge versus cloud deployment trade-offs
\end{enumerate}

\section{Technical Approach}

\subsection{Technology Stack}
The project uses Python for backend development, Hugging Face Transformers for model management, Home Assistant REST API for device communication, and Docker with K3s for container orchestration across a Raspberry Pi cluster.

\subsection{Model Selection and Deployment}
Given 4GB Raspberry Pi 4B memory constraints, we will use quantized language models: TinyLlama-1.1B-Chat~\cite{zhang2023tinyllama} or Phi-2 with Q4 quantization~\cite{gunasekara2023textbooks} (reducing from 6GB to 1.6GB). Models will be fine-tuned on smart home command datasets while maintaining the compact footprint for local deployment.

\subsection{Infrastructure Design}
The system deploys on a 4-node Raspberry Pi 4B cluster using K3s~\cite{k3s2019} (requires 512MB RAM per node, leaving ~3GB for applications). Configuration includes one master node for orchestration and three worker nodes for distributed services.

\subsection{Backend and Integration}
FastAPI backend provides robust API endpoints for model inference and device communication. Direct Home Assistant integration through REST API and WebSocket connections leverages HA's device abstraction layer, eliminating intermediate messaging protocols and reducing complexity.

\subsection{Context Management and Optimization}
The system implements conversation history and device state tracking within memory constraints. Context awareness uses efficient data structures for recent interactions and device states. Optimization techniques include model quantization, efficient memory management, and intelligent caching for responsive performance on 4GB nodes.

\section{Motivation and Feasibility}

This project aligns with my interests in conversational AI and home automation. I have existing experience with HomeAssistant on Kubernetes, operational smart home devices, and academic preparation in NLP, Machine Learning, and Distributed Systems.

The project scope is achievable within the timeframe using:
\begin{itemize}
\item Existing lightweight, open-source LLMs with proven performance on constrained hardware
\item Established HomeAssistant environment for immediate testing
\item Well-defined smart home functionality subset optimized for edge deployment
\item Iterative development with clear milestones accounting for 4GB Pi limitations
\end{itemize}

Hardware constraints enhance academic value by demonstrating real-world edge deployment challenges. The modular system allows incremental progress with measurable metrics.

\section{Expected Outcomes}

GPT-Home will demonstrate:
\begin{itemize}
\item Effective natural language understanding for smart home control on edge hardware
\item Functional contextual awareness despite memory limitations
\item Privacy-first architecture operating entirely offline
\item Scalable edge AI framework with performance benchmarks comparing edge versus cloud deployment
\end{itemize}

This contributes to edge computing, applied NLP, and smart home technology by showing how optimized language models deliver practical functionality on resource-constrained hardware while addressing privacy, latency, and connectivity concerns.

\section{Conclusion}

GPT-Home represents a novel approach to smart home usability and privacy challenges through edge-deployed conversational AI. By demonstrating successful deployment of optimized language models on resource-constrained hardware, this project contributes practical knowledge to edge AI applications and validates the feasibility of local conversational AI deployment for smart home automation.

\section{My Home Lab Setup}

The development environment for this project leverages my existing home infrastructure, which provides an ideal testbed for edge AI experimentation. The current Raspberry Pi cluster running in my basement serves as the foundation for GPT-Home development and demonstrates the practical viability of running sophisticated AI workloads on affordable, consumer-grade hardware in a typical residential environment.

\begin{figure}[h]
\centering
\begin{minipage}{0.45\textwidth}
\centering
\includegraphics[width=\textwidth,angle=-90]{pi-cluster-basement.jpeg}
\caption{4-node Raspberry Pi 4B cluster running K3s}
\label{fig:pi-cluster}
\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
\centering
\includegraphics[width=\textwidth,angle=-90]{server-rack-setup.jpeg}
\caption{Complete home lab server rack infrastructure}
\label{fig:server-rack}
\end{minipage}
\end{figure}

The cluster operates continuously, managing various home automation tasks while providing the computational foundation for developing and testing conversational AI capabilities. The basement location ensures stable temperatures and network connectivity while showcasing how edge AI can be seamlessly integrated into existing home infrastructure. The broader server rack setup demonstrates the comprehensive nature of the home lab environment supporting this research.

\bibliographystyle{plain}
\bibliography{references}

\end{document}